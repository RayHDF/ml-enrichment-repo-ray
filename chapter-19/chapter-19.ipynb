{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFXIv9qNpKzt",
        "tags": []
      },
      "source": [
        "# Chapter 9 - Training and Deploying at Scale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise\n",
        "\n",
        "1. **What does a SavedModel contain? How do you inspect its content?**\n",
        "   \n",
        "   SavedModel berisi graph definition, variable values, assets, signature definitions, dan metadata model.\n",
        "   \n",
        "   Untuk inspect: `saved_model_cli show --dir my_model --all` atau `tf.saved_model.load(\"my_model\")`\n",
        "\n",
        "2. **When should you use TF Serving? What are its main features? What are some tools you can use to deploy it?**\n",
        "   \n",
        "   Gunakan TF Serving untuk production serving dengan high performance, model versioning, dan scalability.\n",
        "   \n",
        "   Main features: high performance, model versioning, hot-swapping, request batching, monitoring.\n",
        "   \n",
        "   Tools: Docker, Kubernetes, Google Cloud AI Platform, AWS SageMaker, Azure ML.\n",
        "\n",
        "3. **How do you deploy a model across multiple TF Serving instances?**\n",
        "   \n",
        "   Gunakan load balancer untuk distribute requests, deploy containers di multiple servers, gunakan Kubernetes untuk orchestration, dan shared storage untuk model files.\n",
        "\n",
        "4. **When should you use the gRPC API rather than the REST API to query a model served by TF Serving?**\n",
        "   \n",
        "   Gunakan gRPC untuk lower latency, higher throughput, high-frequency requests, dan binary data. Gunakan REST untuk debugging, web integration, dan kemudahan penggunaan.\n",
        "\n",
        "5. **What are the different ways TFLite reduces a model's size to make it run on a mobile or embedded device?**\n",
        "   \n",
        "   TFLite mengurangi ukuran melalui quantization (float32 ke int8), pruning, weight clustering, knowledge distillation, dan operator fusion.\n",
        "\n",
        "6. **What is quantization-aware training, and why would you need it?**\n",
        "   \n",
        "   Training dengan simulasi quantization effects untuk mengurangi accuracy loss saat quantization dan menghasilkan model yang lebih robust untuk mobile deployment.\n",
        "\n",
        "7. **What are model parallelism and data parallelism? Why is the latter generally recommended?**\n",
        "   \n",
        "   Model parallelism: model dibagi across devices. Data parallelism: model sama di-copy ke multiple devices.\n",
        "   \n",
        "   Data parallelism direkomendasikan karena lebih mudah implement, scaling linear, dan communication overhead yang predictable.\n",
        "\n",
        "8. **When training a model across multiple servers, what distribution strategies can you use? How do you choose which one to use?**\n",
        "   \n",
        "   Strategies: MirroredStrategy (single machine), MultiWorkerMirroredStrategy (multiple machines), TPUStrategy (TPUs), ParameterServerStrategy (very large models).\n",
        "   \n",
        "   Pilih berdasarkan hardware setup dan model size requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TFSU3FCOpKzu"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Fwz7tOY7MH54"
      },
      "outputs": [],
      "source": [
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "if IS_COLAB:\n",
        "    import os\n",
        "    os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "    import tf_keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0Piq5se2pKzx"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import tensorflow as tf\n",
        "\n",
        "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL_Yl3IWMH54",
        "outputId": "847846a0-42ac-44d6-e9d4-40f0a505af29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "if \"google.colab\" in sys.modules or \"kaggle_secrets\" in sys.modules:\n",
        "    %pip install -q -U google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ekxzo6pOpKzy"
      },
      "outputs": [],
      "source": [
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. Neural nets can be very slow without a GPU.\")\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware \"\n",
        "              \"accelerator.\")\n",
        "    if \"kaggle_secrets\" in sys.modules:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOuLfLsCMH54"
      },
      "source": [
        "# Serving a TensorFlow Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3JBr7ewMH55"
      },
      "source": [
        "### Exporting SavedModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqswYULPMH55",
        "outputId": "7a27fcfe-f55d-4b8e-b1c3-28257bd37cf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 11s 5ms/step - loss: 0.6794 - accuracy: 0.8282 - val_loss: 0.3659 - val_accuracy: 0.9056\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3504 - accuracy: 0.9022 - val_loss: 0.2965 - val_accuracy: 0.9172\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3015 - accuracy: 0.9143 - val_loss: 0.2625 - val_accuracy: 0.9278\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2713 - accuracy: 0.9236 - val_loss: 0.2408 - val_accuracy: 0.9356\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2480 - accuracy: 0.9301 - val_loss: 0.2220 - val_accuracy: 0.9364\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2290 - accuracy: 0.9357 - val_loss: 0.2086 - val_accuracy: 0.9402\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2131 - accuracy: 0.9395 - val_loss: 0.1940 - val_accuracy: 0.9474\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1992 - accuracy: 0.9438 - val_loss: 0.1844 - val_accuracy: 0.9498\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1870 - accuracy: 0.9473 - val_loss: 0.1743 - val_accuracy: 0.9530\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1764 - accuracy: 0.9502 - val_loss: 0.1653 - val_accuracy: 0.9564\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "\n",
        "# extra code – load and split the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "# extra code – build & train an MNIST model (also handles image preprocessing)\n",
        "tf.random.set_seed(42)\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8),\n",
        "    tf.keras.layers.Rescaling(scale=1 / 255),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "\n",
        "model_name = \"my_mnist_model\"\n",
        "model_version = \"0001\"\n",
        "model_path = Path(model_name) / model_version\n",
        "model.save(model_path, save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjQLVc--MH55",
        "outputId": "d7010b38-0fc7-4957-d885-b391d8c2e984"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['my_mnist_model/0001',\n",
              " 'my_mnist_model/0001/assets',\n",
              " 'my_mnist_model/0001/fingerprint.pb',\n",
              " 'my_mnist_model/0001/keras_metadata.pb',\n",
              " 'my_mnist_model/0001/saved_model.pb',\n",
              " 'my_mnist_model/0001/variables',\n",
              " 'my_mnist_model/0001/variables/variables.data-00000-of-00001',\n",
              " 'my_mnist_model/0001/variables/variables.index']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted([str(path) for path in model_path.parent.glob(\"**/*\")])  # extra code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl0Cg_KIMH56"
      },
      "source": [
        "### Installing and Starting TensorFlow Serving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BwRf6u9MH56",
        "outputId": "4ac4c376-c5b8-4998-901f-30a49c8e4404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "100  2943  100  2943    0     0   8027      0 --:--:-- --:--:-- --:--:--  8019\n",
            "OK\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,765 kB]\n",
            "Get:7 https://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,026 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,744 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,017 kB]\n",
            "Get:13 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [342 B]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:16 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [347 B]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,984 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,553 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,295 kB]\n",
            "Fetched 21.8 MB in 2s (10.4 MB/s)\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "\u001b[1;33mW: \u001b[0mhttps://storage.googleapis.com/tensorflow-serving-apt/dists/stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 649 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.19.0 [649 MB]\n",
            "Fetched 649 MB in 10s (63.7 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.19.0_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.19.0) ...\n",
            "Setting up tensorflow-model-server (2.19.0) ...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "if \"google.colab\" in sys.modules or \"kaggle_secrets\" in sys.modules:\n",
        "    url = \"https://storage.googleapis.com/tensorflow-serving-apt\"\n",
        "    src = \"stable tensorflow-model-server tensorflow-model-server-universal\"\n",
        "    !echo 'deb {url} {src}' > /etc/apt/sources.list.d/tensorflow-serving.list\n",
        "    !curl '{url}/tensorflow-serving.release.pub.gpg' | apt-key add -\n",
        "    !apt update -q && apt-get install -y tensorflow-model-server\n",
        "    %pip install -q -U tensorflow-serving-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wpxWLHvTMH56"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"MODEL_DIR\"] = str(model_path.parent.absolute())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rvTCvq7iMH56"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "tensorflow_model_server \\\n",
        "    --port=8500 \\\n",
        "    --rest_api_port=8501 \\\n",
        "    --model_name=my_mnist_model \\\n",
        "    --model_base_path=\"${MODEL_DIR}\" >my_server.log 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pk6TE0BJMH56"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "time.sleep(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9zpyCp2MH57"
      },
      "source": [
        "### Menggunakan REST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cdkFHzxnMH57"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "X_new = X_test[:3] \n",
        "request_json = json.dumps({\n",
        "    \"signature_name\": \"serving_default\",\n",
        "    \"instances\": X_new.tolist(),\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "R1Z1_19NMH57",
        "outputId": "8ce302b6-fbd7-423b-9ab2-a55ffe2e35d0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"signature_name\": \"serving_default\", \"instances\": [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0..., 0, 0]]]}'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "request_json[:100] + \"...\" + request_json[-10:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jwc4F1_eMH57"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "server_url = \"http://localhost:8501/v1/models/my_mnist_model:predict\"\n",
        "response = requests.post(server_url, data=request_json)\n",
        "response.raise_for_status() \n",
        "response = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TktfvEL1MH57",
        "outputId": "8d314aee-f920-4f00-fa8a-c91368883667"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.98, 0.01, 0.  , 0.  , 0.01, 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.98, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "y_proba = np.array(response[\"predictions\"])\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWB8vv5EMH57"
      },
      "source": [
        "### Menggunakan grpc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wu2z6SNRMH57"
      },
      "outputs": [],
      "source": [
        "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
        "\n",
        "request = PredictRequest()\n",
        "request.model_spec.name = model_name\n",
        "request.model_spec.signature_name = \"serving_default\"\n",
        "input_name = model.input_names[0] \n",
        "request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UVW28_f4MH57"
      },
      "outputs": [],
      "source": [
        "import grpc\n",
        "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
        "\n",
        "channel = grpc.insecure_channel('localhost:8500')\n",
        "predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
        "response = predict_service.Predict(request, timeout=10.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "X8wSkujWMH57",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "y_proba = tf.make_ndarray(outputs_proto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GCJgvThMH57",
        "outputId": "0e0bb627-1b06-45d0-9cd8-cf6416964bf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.98, 0.01, 0.  , 0.  , 0.01, 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.98, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XPU6zJsMH58",
        "outputId": "24d706ea-80cf-43e3-a3e7-a73761210b2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.98, 0.01, 0.  , 0.  , 0.01, 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.98, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# extra code – shows how to avoid using tf.make_ndarray()\n",
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "shape = [dim.size for dim in outputs_proto.tensor_shape.dim]\n",
        "y_proba = np.array(outputs_proto.float_val).reshape(shape)\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43psQ1VTMH58"
      },
      "source": [
        "### Deploying versi baru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vYHAt2dMH58",
        "outputId": "cc8a5123-683f-4b27-c37d-07229588f446",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.7648 - accuracy: 0.7945 - val_loss: 0.3583 - val_accuracy: 0.9044\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3279 - accuracy: 0.9066 - val_loss: 0.2764 - val_accuracy: 0.9232\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2715 - accuracy: 0.9214 - val_loss: 0.2367 - val_accuracy: 0.9334\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2382 - accuracy: 0.9310 - val_loss: 0.2130 - val_accuracy: 0.9404\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2148 - accuracy: 0.9371 - val_loss: 0.1953 - val_accuracy: 0.9434\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1971 - accuracy: 0.9431 - val_loss: 0.1833 - val_accuracy: 0.9458\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1825 - accuracy: 0.9475 - val_loss: 0.1700 - val_accuracy: 0.9518\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1704 - accuracy: 0.9505 - val_loss: 0.1628 - val_accuracy: 0.9534\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1601 - accuracy: 0.9541 - val_loss: 0.1526 - val_accuracy: 0.9570\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1513 - accuracy: 0.9564 - val_loss: 0.1459 - val_accuracy: 0.9586\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8),\n",
        "    tf.keras.layers.Rescaling(scale=1 / 255),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yE2G5R41MH58"
      },
      "outputs": [],
      "source": [
        "model_version = \"0002\"\n",
        "model_path = Path(model_name) / model_version\n",
        "model.save(model_path, save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f65URBHrMH58",
        "outputId": "6ea5e15b-bd9d-4b93-e504-b0c4072fe5b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['my_mnist_model/0001',\n",
              " 'my_mnist_model/0001/assets',\n",
              " 'my_mnist_model/0001/fingerprint.pb',\n",
              " 'my_mnist_model/0001/keras_metadata.pb',\n",
              " 'my_mnist_model/0001/saved_model.pb',\n",
              " 'my_mnist_model/0001/variables',\n",
              " 'my_mnist_model/0001/variables/variables.data-00000-of-00001',\n",
              " 'my_mnist_model/0001/variables/variables.index',\n",
              " 'my_mnist_model/0002',\n",
              " 'my_mnist_model/0002/assets',\n",
              " 'my_mnist_model/0002/fingerprint.pb',\n",
              " 'my_mnist_model/0002/keras_metadata.pb',\n",
              " 'my_mnist_model/0002/saved_model.pb',\n",
              " 'my_mnist_model/0002/variables',\n",
              " 'my_mnist_model/0002/variables/variables.data-00000-of-00001',\n",
              " 'my_mnist_model/0002/variables/variables.index']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted([str(path) for path in model_path.parent.glob(\"**/*\")])  # extra code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uTSA5A0DMH58"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "server_url = \"http://localhost:8501/v1/models/my_mnist_model:predict\"\n",
        "\n",
        "response = requests.post(server_url, data=request_json)\n",
        "response.raise_for_status()\n",
        "response = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_ailQRcMH58",
        "outputId": "ce0666b8-4702-4e51-c53f-22fa545c1fdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['predictions'])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4l25EB-MH58",
        "outputId": "f42fe3d4-68d2-4c48-a65d-3bae78d821ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.98, 0.01, 0.  , 0.  , 0.01, 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.98, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_proba = np.array(response[\"predictions\"])\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQym82jIMH5-"
      },
      "source": [
        "## Deploying TF Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "fNE2gQ6UMH5-"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(str(model_path))\n",
        "tflite_model = converter.convert()\n",
        "with open(\"my_converted_savedmodel.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "iLEA7FloMH5-"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Vp3pvTPgMH5-"
      },
      "outputs": [],
      "source": [
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "w5BmW4TmMH5-"
      },
      "outputs": [],
      "source": [
        "tflite_model = converter.convert()\n",
        "with open(\"my_converted_keras_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YofIqviMH5_"
      },
      "source": [
        "## Menggunakan GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvteVEYrMH5_",
        "outputId": "ed9135c5-1a6f-40f4-fa53-b34da0cee7e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "physical_gpus"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
